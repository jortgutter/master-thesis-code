{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecc0db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "from tonic import transforms\n",
    "import tonic\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_nmnist_dataset(timestep_size, sensor_width):\n",
    "    h,w = sensor_width, sensor_width\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Downsample(spatial_factor=sensor_width / 34.0),\n",
    "        transforms.ToFrame(sensor_size=(h,w,2), time_window=timestep_size),\n",
    "        torch.from_numpy,\n",
    "    ])\n",
    "    train_dataset = tonic.datasets.NMNIST(save_to=\"./n_mnist/data_small\", transform=transform, train=True, first_saccade_only=True)\n",
    "    test_dataset = tonic.datasets.NMNIST(save_to=\"./n_mnist/data_small\", transform=transform, train=False, first_saccade_only=True)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = get_nmnist_dataset(100000, 12)\n",
    "trainloader = DataLoader(train_dataset, batch_size=128, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=1024, collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af57519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:34<00:00, 13.74it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.6128 | Train Acc: 0.7738 | Test Loss: 1.5348 | Test Acc: 0.8664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:32<00:00, 14.32it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 1.5722 | Train Acc: 0.8244 | Test Loss: 1.5268 | Test Acc: 0.8907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:34<00:00, 13.69it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 1.5567 | Train Acc: 0.8454 | Test Loss: 1.5217 | Test Acc: 0.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:39<00:00, 12.01it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 1.5476 | Train Acc: 0.8577 | Test Loss: 1.5215 | Test Acc: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:57<00:00,  8.19it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 1.5418 | Train Acc: 0.8660 | Test Loss: 1.5197 | Test Acc: 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:45<00:00, 10.25it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 1.5376 | Train Acc: 0.8720 | Test Loss: 1.5228 | Test Acc: 0.8963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:44<00:00, 10.65it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 1.5348 | Train Acc: 0.8760 | Test Loss: 1.5187 | Test Acc: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:46<00:00, 10.04it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 1.5323 | Train Acc: 0.8795 | Test Loss: 1.5182 | Test Acc: 0.8874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:30<00:00, 15.50it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 1.5304 | Train Acc: 0.8824 | Test Loss: 1.5163 | Test Acc: 0.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:30<00:00, 15.35it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 1.5288 | Train Acc: 0.8849 | Test Loss: 1.5183 | Test Acc: 0.9044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Some of this comes from: https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_7.html\n",
    "\n",
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.atan()\n",
    "beta = 1.0 # No decay\n",
    "\n",
    "#  Initialize Network\n",
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(12*12*2, 64),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Linear(64, 10),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True),\n",
    "                    ).to(device)\n",
    "\n",
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    mem_rec = []\n",
    "    utils.reset(net)\n",
    "\n",
    "    for step in range(data.size(0)):\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "        mem_rec.append(mem_out)\n",
    "\n",
    "    return torch.stack(spk_rec), torch.stack(mem_rec)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "loss_fn = SF.ce_rate_loss()\n",
    "\n",
    "num_epochs = 10\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "test_loss_hist = []\n",
    "test_acc_hist = []\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the network\n",
    "    net.train()\n",
    "    for data, targets in tqdm(iter(trainloader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = forward_pass(net, data)\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        train_loss_hist.append(loss_val.item())\n",
    "        acc = SF.accuracy_rate(spk_rec, targets)\n",
    "        train_acc_hist.append(acc)\n",
    "\n",
    "    # Test the network\n",
    "    net.eval()\n",
    "    test_losses_epoch = []\n",
    "    test_accs_epoch = []\n",
    "    batch_sizes = []\n",
    "    for data, targets in tqdm(iter(testloader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        spk_rec, mem_rec = forward_pass(net, data)\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        test_losses_epoch.append(loss_val.item())\n",
    "        acc = SF.accuracy_rate(spk_rec, targets)\n",
    "        test_accs_epoch.append(acc)\n",
    "        batch_sizes.append(data.size(0))\n",
    "    test_loss_hist.append(np.average(test_losses_epoch, weights=batch_sizes))\n",
    "    test_acc_hist.append(np.average(test_accs_epoch, weights=batch_sizes))\n",
    "\n",
    "    # Print training and testing statistics\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {np.mean(train_loss_hist):.4f} | Train Acc: {np.mean(train_acc_hist):.4f} | Test Loss: {test_loss_hist[-1]:.4f} | Test Acc: {test_acc_hist[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edeb3da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
